{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "55cf54c6-60c1-4def-a8a2-996d89cf8d96",
    "_uuid": "04ecd3cd795b6e4cf4ff048c1f00601ef69f8e95"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from plotly import tools\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "MAIN_PATH = '../input/'\n",
    "df = pd.read_csv(MAIN_PATH +'bank.csv')\n",
    "term_deposits = df.copy()\n",
    "# Have a grasp of how our data looks.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "49bb0e1d-ea5d-43fb-a62e-89ec2cf0248e",
    "_kg_hide-input": true,
    "_uuid": "001b540f01383cdf4817cf2a3ae1d0467a35bf0d"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "22f978f6-39e7-45ea-8061-04b23bce004c",
    "_uuid": "b881241ef51fdc4fd3f59b245b78afe2c60bf796"
   },
   "source": [
    "Fortunately, there are no <b>missing values</b>. If there were missing values we will have to fill them with the median, mean or mode. I tend to use the median but in this scenario there is no need to fill any missing values. This will definitely make our job easier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0bf2d612-22d9-4263-997f-7842032223d4",
    "_kg_hide-input": true,
    "_uuid": "1bce354de17ec340c6e9fe7f9aff1b7ffaeef823"
   },
   "outputs": [],
   "source": [
    "# No missing values.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5c15933c3f2ae7fe44dde70f69dd96fe8f3a612b"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,2, figsize=(16,8))\n",
    "\n",
    "colors = [\"#FA5858\", \"#64FE2E\"]\n",
    "labels =\"Did not Open Term Suscriptions\", \"Opened Term Suscriptions\"\n",
    "\n",
    "plt.suptitle('Information on Term Suscriptions', fontsize=20)\n",
    "\n",
    "df[\"deposit\"].value_counts().plot.pie(explode=[0,0.25], autopct='%1.2f%%', ax=ax[0], shadow=True, colors=colors, \n",
    "                                             labels=labels, fontsize=12, startangle=25)\n",
    "\n",
    "\n",
    "# ax[0].set_title('State of Loan', fontsize=16)\n",
    "ax[0].set_ylabel('% of Condition of Loans', fontsize=14)\n",
    "\n",
    "# sns.countplot('loan_condition', data=df, ax=ax[1], palette=colors)\n",
    "# ax[1].set_title('Condition of Loans', fontsize=20)\n",
    "# ax[1].set_xticklabels(['Good', 'Bad'], rotation='horizontal')\n",
    "palette = [\"#64FE2E\", \"#FA5858\"]\n",
    "\n",
    "sns.barplot(x=\"education\", y=\"balance\", hue=\"deposit\", data=df, palette=palette, estimator=lambda x: len(x) / len(df) * 100)\n",
    "ax[1].set(ylabel=\"(%)\")\n",
    "ax[1].set_xticklabels(df[\"education\"].unique(), rotation=0, rotation_mode=\"anchor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "10648601-36e1-464f-83e0-040b59326d1e",
    "_kg_hide-input": true,
    "_uuid": "92706f68c12026775143ec8b6f200cc94f739edd"
   },
   "outputs": [],
   "source": [
    "# Let's see how the numeric data is distributed.\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "df.hist(bins=20, figsize=(14,10), color='#E14906')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "869d4858016402b8a8cd0c6eff5317a59ee3415e"
   },
   "outputs": [],
   "source": [
    "df['deposit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e95bc86ba09f1bd6b04dabbb7fcf1279293c9165"
   },
   "outputs": [],
   "source": [
    "# plt.style.use('dark_background')\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax3 = fig.add_subplot(212)\n",
    "\n",
    "g = sns.boxplot(x=\"default\", y=\"balance\", hue=\"deposit\",\n",
    "                    data=df, palette=\"muted\", ax=ax1)\n",
    "\n",
    "g.set_title(\"Amount of Balance by Term Suscriptions\")\n",
    "\n",
    "# ax.set_xticklabels(df[\"default\"].unique(), rotation=45, rotation_mode=\"anchor\")\n",
    "\n",
    "g1 = sns.boxplot(x=\"job\", y=\"balance\", hue=\"deposit\",\n",
    "                 data=df, palette=\"RdBu\", ax=ax2)\n",
    "\n",
    "g1.set_xticklabels(df[\"job\"].unique(), rotation=90, rotation_mode=\"anchor\")\n",
    "g1.set_title(\"Type of Work by Term Suscriptions\")\n",
    "\n",
    "g2 = sns.violinplot(data=df, x=\"education\", y=\"balance\", hue=\"deposit\", palette=\"RdBu_r\")\n",
    "\n",
    "g2.set_title(\"Distribution of Balance by Education\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1281bd3cca6c5050493a79c9b6c763abdb2de373"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "e6f0164ced43c674d386217be2b8bd3c082269dc"
   },
   "outputs": [],
   "source": [
    "# Drop the Job Occupations that are \"Unknown\"\n",
    "df = df.drop(df.loc[df[\"job\"] == \"unknown\"].index)\n",
    "\n",
    "# Admin and management are basically the same let's put it under the same categorical value\n",
    "lst = [df]\n",
    "\n",
    "for col in lst:\n",
    "    col.loc[col[\"job\"] == \"admin.\", \"job\"] = \"management\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3696d1bce9d029e0277c087b21f22709d36df22b"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "8e01924e81719861c42a6775e42eca5188ea3dcd"
   },
   "outputs": [],
   "source": [
    "import squarify\n",
    "df = df.drop(df.loc[df[\"balance\"] == 0].index)\n",
    "\n",
    "\n",
    "x = 0\n",
    "y = 0\n",
    "width = 100\n",
    "height = 100\n",
    "\n",
    "job_names = df['job'].value_counts().index\n",
    "values = df['job'].value_counts().tolist()\n",
    "\n",
    "normed = squarify.normalize_sizes(values, width, height)\n",
    "rects = squarify.squarify(normed, x, y, width, height)\n",
    "\n",
    "colors = ['rgb(200, 255, 144)','rgb(135, 206, 235)',\n",
    "          'rgb(235, 164, 135)','rgb(220, 208, 255)',\n",
    "          'rgb(253, 253, 150)','rgb(255, 127, 80)', \n",
    "         'rgb(218, 156, 133)', 'rgb(245, 92, 76)',\n",
    "         'rgb(252,64,68)', 'rgb(154,123,91)']\n",
    "\n",
    "shapes = []\n",
    "annotations = []\n",
    "counter = 0\n",
    "\n",
    "for r in rects:\n",
    "    shapes.append(\n",
    "        dict(\n",
    "            type = 'rect',\n",
    "            x0 = r['x'],\n",
    "            y0 = r['y'],\n",
    "            x1 = r['x'] + r['dx'],\n",
    "            y1 = r['y'] + r['dy'],\n",
    "            line = dict(width=2),\n",
    "            fillcolor = colors[counter]\n",
    "        )\n",
    "    )\n",
    "    annotations.append(\n",
    "        dict(\n",
    "            x = r['x']+(r['dx']/2),\n",
    "            y = r['y']+(r['dy']/2),\n",
    "            text = values[counter],\n",
    "            showarrow = False\n",
    "        )\n",
    "    )\n",
    "    counter = counter + 1\n",
    "    if counter >= len(colors):\n",
    "        counter = 0\n",
    "    \n",
    "# For hover text\n",
    "trace0 = go.Scatter(\n",
    "    x = [ r['x']+(r['dx']/2) for r in rects],\n",
    "    y = [ r['y']+(r['dy']/2) for r in rects],\n",
    "    text = [ str(v) for v in job_names],\n",
    "    mode='text',\n",
    ")\n",
    "\n",
    "layout = dict(\n",
    "    title='Number of Occupations <br> <i>(From our Sample Population)</i>',\n",
    "    height=700, \n",
    "    width=700,\n",
    "    xaxis=dict(showgrid=False,zeroline=False),\n",
    "    yaxis=dict(showgrid=False,zeroline=False),\n",
    "    shapes=shapes,\n",
    "    annotations=annotations,\n",
    "    hovermode='closest'\n",
    ")\n",
    "\n",
    "# With hovertext\n",
    "figure = dict(data=[trace0], layout=layout)\n",
    "\n",
    "iplot(figure, filename='squarify-treemap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "e6aeb678daa10227dfd875d69721184b6edcd4d4"
   },
   "outputs": [],
   "source": [
    "# Now let's see which occupation tended to have more balance in their accounts\n",
    "\n",
    "suscribed_df = df.loc[df[\"deposit\"] == \"yes\"]\n",
    "\n",
    "occupations = df[\"job\"].unique().tolist()\n",
    "\n",
    "# Get the balances by jobs\n",
    "management = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"management\"].values\n",
    "technician = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"technician\"].values\n",
    "services = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"services\"].values\n",
    "retired = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"retired\"].values\n",
    "blue_collar = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"blue-collar\"].values\n",
    "unemployed = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"unemployed\"].values\n",
    "entrepreneur = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"entrepreneur\"].values\n",
    "housemaid = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"housemaid\"].values\n",
    "self_employed = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"self-employed\"].values\n",
    "student = suscribed_df[\"age\"].loc[suscribed_df[\"job\"] == \"student\"].values\n",
    "\n",
    "\n",
    "ages = [management, technician, services, retired, blue_collar, unemployed, \n",
    "         entrepreneur, housemaid, self_employed, student]\n",
    "\n",
    "colors = ['rgba(93, 164, 214, 0.5)', 'rgba(255, 144, 14, 0.5)',\n",
    "          'rgba(44, 160, 101, 0.5)', 'rgba(255, 65, 54, 0.5)', \n",
    "          'rgba(207, 114, 255, 0.5)', 'rgba(127, 96, 0, 0.5)',\n",
    "         'rgba(229, 126, 56, 0.5)', 'rgba(229, 56, 56, 0.5)',\n",
    "         'rgba(174, 229, 56, 0.5)', 'rgba(229, 56, 56, 0.5)']\n",
    "\n",
    "traces = []\n",
    "\n",
    "for xd, yd, cls in zip(occupations, ages, colors):\n",
    "        traces.append(go.Box(\n",
    "            y=yd,\n",
    "            name=xd,\n",
    "            boxpoints='all',\n",
    "            jitter=0.5,\n",
    "            whiskerwidth=0.2,\n",
    "            fillcolor=cls,\n",
    "            marker=dict(\n",
    "                size=2,\n",
    "            ),\n",
    "            line=dict(width=1),\n",
    "        ))\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Distribution of Ages by Occupation',\n",
    "    yaxis=dict(\n",
    "        autorange=True,\n",
    "        showgrid=True,\n",
    "        zeroline=True,\n",
    "        dtick=5,\n",
    "        gridcolor='rgb(255, 255, 255)',\n",
    "        gridwidth=1,\n",
    "        zerolinecolor='rgb(255, 255, 255)',\n",
    "        zerolinewidth=2,\n",
    "    ),\n",
    "    margin=dict(\n",
    "        l=40,\n",
    "        r=30,\n",
    "        b=80,\n",
    "        t=100,\n",
    "    ),\n",
    "    paper_bgcolor='rgb(224,255,246)',\n",
    "    plot_bgcolor='rgb(251,251,251)',\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=traces, layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "192aba77e8b1c4585913ff064bbdf0b36ed90e65"
   },
   "outputs": [],
   "source": [
    "# Balance Distribution\n",
    "\n",
    "# Create a Balance Category\n",
    "df[\"balance_status\"] = np.nan\n",
    "lst = [df]\n",
    "\n",
    "for col in lst:\n",
    "    col.loc[col[\"balance\"] < 0, \"balance_status\"] = \"negative\"\n",
    "    col.loc[(col[\"balance\"] >= 0) & (col[\"balance\"] <= 30000), \"balance_status\"] = \"low\"\n",
    "    col.loc[(col[\"balance\"] > 30000) & (col[\"balance\"] <= 40000), \"balance_status\"] = \"middle\"\n",
    "    col.loc[col[\"balance\"] > 40000, \"balance_status\"] = \"high\"\n",
    "    \n",
    "# balance by balance_status\n",
    "negative = df[\"balance\"].loc[df[\"balance_status\"] == \"negative\"].values.tolist()\n",
    "low = df[\"balance\"].loc[df[\"balance_status\"] == \"low\"].values.tolist()\n",
    "middle = df[\"balance\"].loc[df[\"balance_status\"] == \"middle\"].values.tolist()\n",
    "high = df[\"balance\"].loc[df[\"balance_status\"] == \"high\"].values.tolist()\n",
    "\n",
    "\n",
    "# Get the average by occupation in each balance category\n",
    "job_balance = df.groupby(['job', 'balance_status'])['balance'].mean()\n",
    "\n",
    "\n",
    "trace1 = go.Barpolar(\n",
    "    r=[-199.0, -392.0, -209.0, -247.0, -233.0, -270.0, -271.0, 0, -276.0, -134.5],\n",
    "    text=[\"blue-collar\", \"entrepreneur\", \"housemaid\", \"management\", \"retired\", \"self-employed\",\n",
    "         \"services\", \"student\", \"technician\", \"unemployed\"],\n",
    "    name='Negative Balance',\n",
    "    marker=dict(\n",
    "        color='rgb(246, 46, 46)'\n",
    "    )\n",
    ")\n",
    "trace2 = go.Barpolar(\n",
    "    r=[319.5, 283.0, 212.0, 313.0, 409.0, 274.5, 308.5, 253.0, 316.0, 330.0],\n",
    "    text=[\"blue-collar\", \"entrepreneur\", \"housemaid\", \"management\", \"retired\", \"self-employed\",\n",
    "         \"services\", \"student\", \"technician\", \"unemployed\"],\n",
    "    name='Low Balance',\n",
    "    marker=dict(\n",
    "        color='rgb(246, 97, 46)'\n",
    "    )\n",
    ")\n",
    "trace3 = go.Barpolar(\n",
    "    r=[2128.5, 2686.0, 2290.0, 2366.0, 2579.0, 2293.5, 2005.5, 2488.0, 2362.0, 1976.0],\n",
    "    text=[\"blue-collar\", \"entrepreneur\", \"housemaid\", \"management\", \"retired\", \"self-employed\",\n",
    "         \"services\", \"student\", \"technician\", \"unemployed\"],\n",
    "    name='Middle Balance',\n",
    "    marker=dict(\n",
    "        color='rgb(246, 179, 46)'\n",
    "    )\n",
    ")\n",
    "trace4 = go.Barpolar(\n",
    "    r=[14247.5, 20138.5, 12278.5, 12956.0, 20723.0, 12159.0, 12223.0, 13107.0, 12063.0, 15107.5],\n",
    "    text=[\"blue-collar\", \"entrepreneur\", \"housemaid\", \"management\", \"retired\", \"self-employed\",\n",
    "         \"services\", \"student\", \"technician\", \"unemployed\"],\n",
    "    name='High Balance',\n",
    "    marker=dict(\n",
    "        color='rgb(46, 246, 78)'\n",
    "    )\n",
    ")\n",
    "data = [trace1, trace2, trace3, trace4]\n",
    "layout = go.Layout(\n",
    "    title='Mean Balance in Account<br> <i> by Job Occupation</i>',\n",
    "    font=dict(\n",
    "        size=12\n",
    "    ),\n",
    "    legend=dict(\n",
    "        font=dict(\n",
    "            size=16\n",
    "        )\n",
    "    ),\n",
    "    radialaxis=dict(\n",
    "        ticksuffix='%'\n",
    "    ),\n",
    "    orientation=270\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig, filename='polar-area-chart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "233f669cdb562c52a0edab979c2933c89451d0c1"
   },
   "outputs": [],
   "source": [
    "df['marital'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "632f06ccddbe410aaccf6b7a432ffe56108aa47f"
   },
   "outputs": [],
   "source": [
    "df['marital'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "7c33cfa8f06d7a68f61e2e9eb2658bb021250680"
   },
   "outputs": [],
   "source": [
    "df['marital'].value_counts().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "1eca4c22d89d9ffc1a28fd978629c9ed468c8c5d"
   },
   "outputs": [],
   "source": [
    "vals = df['marital'].value_counts().tolist()\n",
    "labels = ['married', 'divorced', 'single']\n",
    "\n",
    "data = [go.Bar(\n",
    "            x=labels,\n",
    "            y=vals,\n",
    "    marker=dict(\n",
    "    color=\"#FE9A2E\")\n",
    "    )]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"Count by Marital Status\",\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "\n",
    "\n",
    "iplot(fig, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "7b9af53b779d764cd7d020599b4f93fd77ca6da7"
   },
   "outputs": [],
   "source": [
    "# Distribution of Balances by Marital status\n",
    "single = df['balance'].loc[df['marital'] == 'single'].values\n",
    "married = df['balance'].loc[df['marital'] == 'married'].values\n",
    "divorced = df['balance'].loc[df['marital'] == 'divorced'].values\n",
    "\n",
    "\n",
    "single_dist = go.Histogram(\n",
    "    x=single,\n",
    "    histnorm='density', \n",
    "    name='single',\n",
    "    marker=dict(\n",
    "        color='#6E6E6E'\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "married_dist = go.Histogram(\n",
    "    x=married,\n",
    "    histnorm='density', \n",
    "    name='married',\n",
    "    marker=dict(\n",
    "        color='#2E9AFE'\n",
    "    )\n",
    ")\n",
    "\n",
    "divorced_dist = go.Histogram(\n",
    "    x=divorced,\n",
    "    histnorm='density', \n",
    "    name='divorced',\n",
    "    marker=dict(\n",
    "        color='#FA5858'\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig = tools.make_subplots(rows=3, print_grid=False)\n",
    "\n",
    "fig.append_trace(single_dist, 1, 1)\n",
    "fig.append_trace(married_dist, 2, 1)\n",
    "fig.append_trace(divorced_dist, 3, 1)\n",
    "\n",
    "\n",
    "fig['layout'].update(showlegend=False, title=\"Price Distributions by Marital Status\",\n",
    "                    height=1000, width=800)\n",
    "\n",
    "iplot(fig, filename='custom-sized-subplot-with-subplot-titles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7432c1f26dff9860ce72b62d081e10685af1a7f5"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c4043538cb050f7a6d4fc61530c38fa004c7ed89"
   },
   "outputs": [],
   "source": [
    "# Notice how divorced have a considerably low amount of balance.\n",
    "fig = ff.create_facet_grid(\n",
    "    df,\n",
    "    x='duration',\n",
    "    y='balance',\n",
    "    color_name='marital',\n",
    "    show_boxes=False,\n",
    "    marker={'size': 10, 'opacity': 1.0},\n",
    "    colormap={'single': 'rgb(165, 242, 242)', 'married': 'rgb(253, 174, 216)', 'divorced': 'rgba(201, 109, 59, 0.82)'}\n",
    ")\n",
    "\n",
    "iplot(fig, filename='facet - custom colormap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "43247a42ea5af2ea429f4b3a888b7d044ef4387f"
   },
   "outputs": [],
   "source": [
    "# Hmmm We have missed some important clients with some high balances. \n",
    "# This shouldn't be happening.\n",
    "fig = ff.create_facet_grid(\n",
    "    df,\n",
    "    y='balance',\n",
    "    facet_row='marital',\n",
    "    facet_col='deposit',\n",
    "    trace_type='box',\n",
    ")\n",
    "\n",
    "iplot(fig, filename='facet - box traces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "57fef8b58e3f3b47448c8dfe2ca8c9fbeffdb351"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "9893d3fe4e2b230ea41172200470b03b77123a18"
   },
   "outputs": [],
   "source": [
    "\n",
    "df = df.drop(df.loc[df[\"education\"] == \"unknown\"].index)\n",
    "df['education'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "6d269bb0db98dca37000d71ccea6fdcbd056c6ce"
   },
   "outputs": [],
   "source": [
    "df['marital/education'] = np.nan\n",
    "lst = [df]\n",
    "\n",
    "for col in lst:\n",
    "    col.loc[(col['marital'] == 'single') & (df['education'] == 'primary'), 'marital/education'] = 'single/primary'\n",
    "    col.loc[(col['marital'] == 'married') & (df['education'] == 'primary'), 'marital/education'] = 'married/primary'\n",
    "    col.loc[(col['marital'] == 'divorced') & (df['education'] == 'primary'), 'marital/education'] = 'divorced/primary'\n",
    "    col.loc[(col['marital'] == 'single') & (df['education'] == 'secondary'), 'marital/education'] = 'single/secondary'\n",
    "    col.loc[(col['marital'] == 'married') & (df['education'] == 'secondary'), 'marital/education'] = 'married/secondary'\n",
    "    col.loc[(col['marital'] == 'divorced') & (df['education'] == 'secondary'), 'marital/education'] = 'divorced/secondary'\n",
    "    col.loc[(col['marital'] == 'single') & (df['education'] == 'tertiary'), 'marital/education'] = 'single/tertiary'\n",
    "    col.loc[(col['marital'] == 'married') & (df['education'] == 'tertiary'), 'marital/education'] = 'married/tertiary'\n",
    "    col.loc[(col['marital'] == 'divorced') & (df['education'] == 'tertiary'), 'marital/education'] = 'divorced/tertiary'\n",
    "    \n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "ad652b23e6677d174bacb5c8fb92b937a8bbec7d"
   },
   "outputs": [],
   "source": [
    "pal = sns.cubehelix_palette(10, rot=-.25, light=.7)\n",
    "g = sns.FacetGrid(df, row=\"marital/education\", hue=\"marital/education\", aspect=12, palette=pal)\n",
    "\n",
    "g.map(sns.kdeplot, \"balance\", clip_on=False, shade=True, alpha=1, lw=1.5, bw=.2)\n",
    "g.map(sns.kdeplot, \"balance\", clip_on=False, color=\"w\", lw=1, bw=0)\n",
    "g.map(plt.axhline, y=0, lw=2, clip_on=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "11fa815fc82afc79c0d2fae3c0cab3a9a8f6de23"
   },
   "outputs": [],
   "source": [
    "education_groups = df.groupby(['marital/education'], as_index=False)['balance'].median()\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sns.barplot(x=\"balance\", y=\"marital/education\", data=education_groups,\n",
    "            label=\"Total\", palette=\"RdBu\")\n",
    "\n",
    "plt.title('Median Balance by Educational/Marital Group', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "bf0f39195c185d682a28aab0129c44ad7ed8eb68"
   },
   "outputs": [],
   "source": [
    "# Let's see the group who had loans from the marital/education group\n",
    "\n",
    "loan_balance = df.groupby(['marital/education', 'loan'], as_index=False)['balance'].median()\n",
    "\n",
    "\n",
    "no_loan = loan_balance['balance'].loc[loan_balance['loan'] == 'no'].values\n",
    "has_loan = loan_balance['balance'].loc[loan_balance['loan'] == 'yes'].values\n",
    "\n",
    "\n",
    "labels = loan_balance['marital/education'].unique().tolist()\n",
    "\n",
    "\n",
    "trace0 = go.Scatter(\n",
    "    x=no_loan,\n",
    "    y=labels,\n",
    "    mode='markers',\n",
    "    name='No Loan',\n",
    "    marker=dict(\n",
    "        color='rgb(175,238,238)',\n",
    "        line=dict(\n",
    "            color='rgb(0,139,139)',\n",
    "            width=1,\n",
    "        ),\n",
    "        symbol='circle',\n",
    "        size=16,\n",
    "    )\n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "    x=has_loan,\n",
    "    y=labels,\n",
    "    mode='markers',\n",
    "    name='Has a Previous Loan',\n",
    "    marker=dict(\n",
    "        color='rgb(250,128,114)',\n",
    "        line=dict(\n",
    "            color='rgb(178,34,34)',\n",
    "            width=1,\n",
    "        ),\n",
    "        symbol='circle',\n",
    "        size=16,\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [trace0, trace1]\n",
    "layout = go.Layout(\n",
    "    title=\"The Impact of Loans to Married/Educational Clusters\",\n",
    "    xaxis=dict(\n",
    "        showgrid=False,\n",
    "        showline=True,\n",
    "        linecolor='rgb(102, 102, 102)',\n",
    "        titlefont=dict(\n",
    "            color='rgb(204, 204, 204)'\n",
    "        ),\n",
    "        tickfont=dict(\n",
    "            color='rgb(102, 102, 102)',\n",
    "        ),\n",
    "        showticklabels=False,\n",
    "        dtick=10,\n",
    "        ticks='outside',\n",
    "        tickcolor='rgb(102, 102, 102)',\n",
    "    ),\n",
    "    margin=dict(\n",
    "        l=140,\n",
    "        r=40,\n",
    "        b=50,\n",
    "        t=80\n",
    "    ),\n",
    "    legend=dict(\n",
    "        font=dict(\n",
    "            size=10,\n",
    "        ),\n",
    "        yanchor='middle',\n",
    "        xanchor='right',\n",
    "    ),\n",
    "    width=1000,\n",
    "    height=800,\n",
    "    paper_bgcolor='rgb(255,250,250)',\n",
    "    plot_bgcolor='rgb(255,255,255)',\n",
    "    hovermode='closest',\n",
    ")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig, filename='lowest-oecd-votes-cast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c36347e88b4ab0866d6a3bd547fc0db87324cda8"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5648949445431448917a6c2571b63cd796769790"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "sns.pairplot(df, hue=\"marital/education\", palette=\"Set1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "be2a18f8a8b814404d14713ed1d6e9c44ad190fe"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c00f4366746d63c9f19f1d6822adbf3f2464b706"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "sns.violinplot(x=\"balance\", y=\"job\", hue=\"deposit\", palette=\"RdBu_r\",\n",
    "            data=df);\n",
    "\n",
    "plt.title(\"Job Distribution of Balances by Deposit Status\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6715e27546ccd5cf59c97c677819c170275ec89a"
   },
   "source": [
    "<h2> <b>Classification Model:</b> </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a1227158f08fd3d7d23b14a2b5cca68fc3e8c32"
   },
   "outputs": [],
   "source": [
    "dep = term_deposits['deposit']\n",
    "term_deposits.drop(labels=['deposit'], axis=1,inplace=True)\n",
    "term_deposits.insert(0, 'deposit', dep)\n",
    "term_deposits.head()\n",
    "# housing has a -20% correlation with deposit let's see how it is distributed.\n",
    "# 52 %\n",
    "term_deposits[\"housing\"].value_counts()/len(term_deposits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1e8365a2431959fa9ce1c52568e7d66aee7a756c"
   },
   "outputs": [],
   "source": [
    "term_deposits[\"loan\"].value_counts()/len(term_deposits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e48052d017060f95d5adf6c9423a17d12256c269"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "# Here we split the data into training and test sets and implement a stratified shuffle split.\n",
    "stratified = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_set, test_set in stratified.split(term_deposits, term_deposits[\"loan\"]):\n",
    "    stratified_train = term_deposits.loc[train_set]\n",
    "    stratified_test = term_deposits.loc[test_set]\n",
    "    \n",
    "stratified_train[\"loan\"].value_counts()/len(df)\n",
    "stratified_test[\"loan\"].value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "692970c0c6d3a27d0c266a6cbe0b25bee5536884"
   },
   "outputs": [],
   "source": [
    "# Separate the labels and the features.\n",
    "train_data = stratified_train # Make a copy of the stratified training set.\n",
    "test_data = stratified_test\n",
    "train_data.shape\n",
    "test_data.shape\n",
    "train_data['deposit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d3a2d7aae42d41a6d24cb11d2f562c21e3888fb5"
   },
   "outputs": [],
   "source": [
    "# Definition of the CategoricalEncoder class, copied from PR #9151.\n",
    "# Just run this cell, or copy it to your code, no need to try to\n",
    "# understand every line.\n",
    "# Code reference Hands on Machine Learning with Scikit Learn and Tensorflow by Aurelien Geron.\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import sparse\n",
    "\n",
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Encode categorical features as a numeric array.\n",
    "    The input to this transformer should be a matrix of integers or strings,\n",
    "    denoting the values taken on by categorical (discrete) features.\n",
    "    The features can be encoded using a one-hot aka one-of-K scheme\n",
    "    (``encoding='onehot'``, the default) or converted to ordinal integers\n",
    "    (``encoding='ordinal'``).\n",
    "    This encoding is needed for feeding categorical data to many scikit-learn\n",
    "    estimators, notably linear models and SVMs with the standard kernels.\n",
    "    Read more in the :ref:`User Guide <preprocessing_categorical_features>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    encoding : str, 'onehot', 'onehot-dense' or 'ordinal'\n",
    "        The type of encoding to use (default is 'onehot'):\n",
    "        - 'onehot': encode the features using a one-hot aka one-of-K scheme\n",
    "          (or also called 'dummy' encoding). This creates a binary column for\n",
    "          each category and returns a sparse matrix.\n",
    "        - 'onehot-dense': the same as 'onehot' but returns a dense array\n",
    "          instead of a sparse matrix.\n",
    "        - 'ordinal': encode the features as ordinal integers. This results in\n",
    "          a single column of integers (0 to n_categories - 1) per feature.\n",
    "    categories : 'auto' or a list of lists/arrays of values.\n",
    "        Categories (unique values) per feature:\n",
    "        - 'auto' : Determine categories automatically from the training data.\n",
    "        - list : ``categories[i]`` holds the categories expected in the ith\n",
    "          column. The passed categories are sorted before encoding the data\n",
    "          (used categories can be found in the ``categories_`` attribute).\n",
    "    dtype : number type, default np.float64\n",
    "        Desired dtype of output.\n",
    "    handle_unknown : 'error' (default) or 'ignore'\n",
    "        Whether to raise an error or ignore if a unknown categorical feature is\n",
    "        present during transform (default is to raise). When this is parameter\n",
    "        is set to 'ignore' and an unknown category is encountered during\n",
    "        transform, the resulting one-hot encoded columns for this feature\n",
    "        will be all zeros.\n",
    "        Ignoring unknown categories is not supported for\n",
    "        ``encoding='ordinal'``.\n",
    "    Attributes\n",
    "    ----------\n",
    "    categories_ : list of arrays\n",
    "        The categories of each feature determined during fitting. When\n",
    "        categories were specified manually, this holds the sorted categories\n",
    "        (in order corresponding with output of `transform`).\n",
    "    Examples\n",
    "    --------\n",
    "    Given a dataset with three features and two samples, we let the encoder\n",
    "    find the maximum value per feature and transform the data to a binary\n",
    "    one-hot encoding.\n",
    "    >>> from sklearn.preprocessing import CategoricalEncoder\n",
    "    >>> enc = CategoricalEncoder(handle_unknown='ignore')\n",
    "    >>> enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])\n",
    "    ... # doctest: +ELLIPSIS\n",
    "    CategoricalEncoder(categories='auto', dtype=<... 'numpy.float64'>,\n",
    "              encoding='onehot', handle_unknown='ignore')\n",
    "    >>> enc.transform([[0, 1, 1], [1, 0, 4]]).toarray()\n",
    "    array([[ 1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.],\n",
    "           [ 0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
    "    See also\n",
    "    --------\n",
    "    sklearn.preprocessing.OneHotEncoder : performs a one-hot encoding of\n",
    "      integer ordinal features. The ``OneHotEncoder assumes`` that input\n",
    "      features take on values in the range ``[0, max(feature)]`` instead of\n",
    "      using the unique values.\n",
    "    sklearn.feature_extraction.DictVectorizer : performs a one-hot encoding of\n",
    "      dictionary items (also handles string-valued features).\n",
    "    sklearn.feature_extraction.FeatureHasher : performs an approximate one-hot\n",
    "      encoding of dictionary items or strings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoding='onehot', categories='auto', dtype=np.float64,\n",
    "                 handle_unknown='error'):\n",
    "        self.encoding = encoding\n",
    "        self.categories = categories\n",
    "        self.dtype = dtype\n",
    "        self.handle_unknown = handle_unknown\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit the CategoricalEncoder to X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape [n_samples, n_feature]\n",
    "            The data to determine the categories of each feature.\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "\n",
    "        if self.encoding not in ['onehot', 'onehot-dense', 'ordinal']:\n",
    "            template = (\"encoding should be either 'onehot', 'onehot-dense' \"\n",
    "                        \"or 'ordinal', got %s\")\n",
    "            raise ValueError(template % self.handle_unknown)\n",
    "\n",
    "        if self.handle_unknown not in ['error', 'ignore']:\n",
    "            template = (\"handle_unknown should be either 'error' or \"\n",
    "                        \"'ignore', got %s\")\n",
    "            raise ValueError(template % self.handle_unknown)\n",
    "\n",
    "        if self.encoding == 'ordinal' and self.handle_unknown == 'ignore':\n",
    "            raise ValueError(\"handle_unknown='ignore' is not supported for\"\n",
    "                             \" encoding='ordinal'\")\n",
    "\n",
    "        X = check_array(X, dtype=np.object, accept_sparse='csc', copy=True)\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        self._label_encoders_ = [LabelEncoder() for _ in range(n_features)]\n",
    "\n",
    "        for i in range(n_features):\n",
    "            le = self._label_encoders_[i]\n",
    "            Xi = X[:, i]\n",
    "            if self.categories == 'auto':\n",
    "                le.fit(Xi)\n",
    "            else:\n",
    "                valid_mask = np.in1d(Xi, self.categories[i])\n",
    "                if not np.all(valid_mask):\n",
    "                    if self.handle_unknown == 'error':\n",
    "                        diff = np.unique(Xi[~valid_mask])\n",
    "                        msg = (\"Found unknown categories {0} in column {1}\"\n",
    "                               \" during fit\".format(diff, i))\n",
    "                        raise ValueError(msg)\n",
    "                le.classes_ = np.array(np.sort(self.categories[i]))\n",
    "\n",
    "        self.categories_ = [le.classes_ for le in self._label_encoders_]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform X using one-hot encoding.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape [n_samples, n_features]\n",
    "            The data to encode.\n",
    "        Returns\n",
    "        -------\n",
    "        X_out : sparse matrix or a 2-d array\n",
    "            Transformed input.\n",
    "        \"\"\"\n",
    "        X = check_array(X, accept_sparse='csc', dtype=np.object, copy=True)\n",
    "        n_samples, n_features = X.shape\n",
    "        X_int = np.zeros_like(X, dtype=np.int)\n",
    "        X_mask = np.ones_like(X, dtype=np.bool)\n",
    "\n",
    "        for i in range(n_features):\n",
    "            valid_mask = np.in1d(X[:, i], self.categories_[i])\n",
    "\n",
    "            if not np.all(valid_mask):\n",
    "                if self.handle_unknown == 'error':\n",
    "                    diff = np.unique(X[~valid_mask, i])\n",
    "                    msg = (\"Found unknown categories {0} in column {1}\"\n",
    "                           \" during transform\".format(diff, i))\n",
    "                    raise ValueError(msg)\n",
    "                else:\n",
    "                    # Set the problematic rows to an acceptable value and\n",
    "                    # continue `The rows are marked `X_mask` and will be\n",
    "                    # removed later.\n",
    "                    X_mask[:, i] = valid_mask\n",
    "                    X[:, i][~valid_mask] = self.categories_[i][0]\n",
    "            X_int[:, i] = self._label_encoders_[i].transform(X[:, i])\n",
    "\n",
    "        if self.encoding == 'ordinal':\n",
    "            return X_int.astype(self.dtype, copy=False)\n",
    "\n",
    "        mask = X_mask.ravel()\n",
    "        n_values = [cats.shape[0] for cats in self.categories_]\n",
    "        n_values = np.array([0] + n_values)\n",
    "        indices = np.cumsum(n_values)\n",
    "\n",
    "        column_indices = (X_int + indices[:-1]).ravel()[mask]\n",
    "        row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),\n",
    "                                n_features)[mask]\n",
    "        data = np.ones(n_samples * n_features)[mask]\n",
    "\n",
    "        out = sparse.csc_matrix((data, (row_indices, column_indices)),\n",
    "                                shape=(n_samples, indices[-1]),\n",
    "                                dtype=self.dtype).tocsr()\n",
    "        if self.encoding == 'onehot-dense':\n",
    "            return out.toarray()\n",
    "        else:\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da24a63d65c5cf19fcbf5ec57a06e682dae2a0f6"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# A class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8d978ce3e64e3d316bcb3e241d4dd9868240adb5"
   },
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c6f9d08d4ae5b059d138fbae9c6e48a54d2231c7"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Making pipelines\n",
    "numerical_pipeline = Pipeline([\n",
    "    (\"select_numeric\", DataFrameSelector([\"age\", \"balance\", \"day\", \"campaign\", \"pdays\", \"previous\",\"duration\"])),\n",
    "    (\"std_scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"select_cat\", DataFrameSelector([\"job\", \"education\", \"marital\", \"default\", \"housing\", \"loan\", \"contact\", \"month\",\n",
    "                                     \"poutcome\"])),\n",
    "    (\"cat_encoder\", CategoricalEncoder(encoding='onehot-dense'))\n",
    "])\n",
    "\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"numerical_pipeline\", numerical_pipeline),\n",
    "        (\"categorical_pipeline\", categorical_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7c40f8e6eafdfa5c4b5d2055fa2f368cd4d07308"
   },
   "outputs": [],
   "source": [
    "X_train = preprocess_pipeline.fit_transform(train_data)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "80bf8dc8ed2468adb524f8eb2429b9ea27b3cbab"
   },
   "outputs": [],
   "source": [
    "y_train = train_data['deposit']\n",
    "y_test = test_data['deposit']\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "28210aa6a40a03c9ff177bcc4f932e8f9b541cd6"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encode = LabelEncoder()\n",
    "y_train = encode.fit_transform(y_train)\n",
    "y_test = encode.fit_transform(y_test)\n",
    "y_train_yes = (y_train == 1)\n",
    "y_train\n",
    "y_train_yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b7d6a5a7613c9ee1d94aca70a7dc07eca782a63b"
   },
   "outputs": [],
   "source": [
    "some_instance = X_train[1250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3d724605d1dd77c122e6a65f2e221ad7aa26ad43"
   },
   "outputs": [],
   "source": [
    "# Time for Classification Models\n",
    "import time\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    " \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "dict_classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Linear SVM\": SVC(),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "    \"Decision Tree\": tree.DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=18),\n",
    "    \"Neural Net\": MLPClassifier(alpha=1),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f1a0b61d476d6bc5d2da3dfb27072d94dddd5585"
   },
   "outputs": [],
   "source": [
    "#  Thanks to Ahspinar for the function. \n",
    "no_classifiers = len(dict_classifiers.keys())\n",
    "\n",
    "def batch_classify(X_train, Y_train, verbose = True):\n",
    "    df_results = pd.DataFrame(data=np.zeros(shape=(no_classifiers,3)), columns = ['classifier', 'train_score', 'training_time'])\n",
    "    count = 0\n",
    "    for key, classifier in dict_classifiers.items():\n",
    "        t_start = time.clock()\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        t_end = time.clock()\n",
    "        t_diff = t_end - t_start\n",
    "        train_score = classifier.score(X_train, Y_train)\n",
    "        df_results.loc[count,'classifier'] = key\n",
    "        df_results.loc[count,'train_score'] = train_score\n",
    "        df_results.loc[count,'training_time'] = t_diff\n",
    "        if verbose:\n",
    "            print(\"trained {c} in {f:.2f} s\".format(c=key, f=t_diff))\n",
    "        count+=1\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ecf17b0bf54b4624af0732ec34922aa9f9c30608"
   },
   "outputs": [],
   "source": [
    "df_results = batch_classify(X_train, y_train)\n",
    "print(df_results.sort_values(by='train_score', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eb72ca11865e63a2bba942afe43a0aa5ccafda3f"
   },
   "outputs": [],
   "source": [
    "# Use Cross-validation.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "                    \n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "log_scores = cross_val_score(log_reg, X_train, y_train, cv=3)\n",
    "log_reg_mean = log_scores.mean()\n",
    "\n",
    "# SVC\n",
    "svc_clf = SVC()\n",
    "svc_scores = cross_val_score(svc_clf, X_train, y_train, cv=3)\n",
    "svc_mean = svc_scores.mean()\n",
    "\n",
    "# KNearestNeighbors\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_scores = cross_val_score(knn_clf, X_train, y_train, cv=3)\n",
    "knn_mean = knn_scores.mean()\n",
    "\n",
    "# Decision Tree\n",
    "tree_clf = tree.DecisionTreeClassifier()\n",
    "tree_scores = cross_val_score(tree_clf, X_train, y_train, cv=3)\n",
    "tree_mean = tree_scores.mean()\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "grad_clf = GradientBoostingClassifier()\n",
    "grad_scores = cross_val_score(grad_clf, X_train, y_train, cv=3)\n",
    "grad_mean = grad_scores.mean()\n",
    "\n",
    "# Random Forest Classifier\n",
    "rand_clf = RandomForestClassifier(n_estimators=18)\n",
    "rand_scores = cross_val_score(rand_clf, X_train, y_train, cv=3)\n",
    "rand_mean = rand_scores.m\n",
    "\n",
    "# NeuralNet Classifier\n",
    "neural_clf = MLPClassifier(alpha=1)\n",
    "neural_scores = cross_val_score(neural_clf, X_train, y_train, cv=3)\n",
    "neural_mean = neural_scores.mean()\n",
    "\n",
    "# Naives Bayes\n",
    "nav_clf = GaussianNB()\n",
    "nav_scores = cross_val_score(nav_clf, X_train, y_train, cv=3)\n",
    "nav_mean = neural_scores.mean()\n",
    "\n",
    "# Create a Dataframe with the results.\n",
    "d = {'Classifiers': ['Logistic Reg.', 'SVC', 'KNN', 'Dec Tree', 'Grad B CLF', 'Rand FC', 'Neural Classifier', 'Naives Bayes'], \n",
    "    'Crossval Mean Scores': [log_reg_mean, svc_mean, knn_mean, tree_mean, grad_mean, rand_mean, neural_mean, nav_mean]}\n",
    "\n",
    "result_df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "438493015531a56fe52feb593861a4cc92c15a6d"
   },
   "outputs": [],
   "source": [
    "# All our models perform well but I will go with GradientBoosting.\n",
    "result_df = result_df.sort_values(by=['Crossval Mean Scores'], ascending=False)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9f9645627070ca75abc65db6d99a67aa822e3203"
   },
   "outputs": [],
   "source": [
    "# Cross validate our Gradient Boosting Classifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(grad_clf, X_train, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0984f57713acf2e96796bc388d680cd29e14c134"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "grad_clf.fit(X_train, y_train)\n",
    "print (\"Gradient Boost Classifier accuracy is %2.2f\" % accuracy_score(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a5179f02a1c96fdecf45bf51c4d3ce86ee665da7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# 4697: no's, 4232: yes\n",
    "conf_matrix = confusion_matrix(y_train, y_train_pred)\n",
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", linewidths=.5, ax=ax)\n",
    "plt.title(\"Confusion Matrix\", fontsize=20)\n",
    "plt.subplots_adjust(left=0.15, right=0.99, bottom=0.15, top=0.99)\n",
    "ax.set_yticks(np.arange(conf_matrix.shape[0]) + 0.5, minor=False)\n",
    "ax.set_xticklabels(\"\")\n",
    "ax.set_yticklabels(['Refused T. Deposits', 'Accepted T. Deposits'], fontsize=16, rotation=360)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5b2bd7589bd4d98a22b6cceabcd1c637fdd139fc"
   },
   "outputs": [],
   "source": [
    "# Let's find the scores  for precision and recall.\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "# The model is 77% sure that the potential client will suscribe to a term deposit. \n",
    "# The model is only retaining 60% of clients that agree to suscribe a term deposit.\n",
    "print('Precision Score: ', precision_score(y_train, y_train_pred))\n",
    "# The classifier only detects 60% of potential clients that will suscribe to a term deposit.\n",
    "print('Recall Score: ', recall_score(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c27318db426e6226331ce1a5558e0c4e9d7fc8a9"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2ee842bdb4299a2ced6e5a43fdeee3a0ccc85da7"
   },
   "outputs": [],
   "source": [
    "y_scores = grad_clf.decision_function([some_instance])\n",
    "y_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d1838ee7172ea11daa91855495372367c8fa6aa3"
   },
   "outputs": [],
   "source": [
    "# Increasing the threshold decreases the recall.\n",
    "threshold = 0\n",
    "y_some_digit_pred = (y_scores > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03bdc6f68008a4c485b6e0d8bfcb9b83786919f5"
   },
   "outputs": [],
   "source": [
    "y_scores = cross_val_predict(grad_clf, X_train, y_train, cv=3, method=\"decision_function\")\n",
    "neural_y_scores = cross_val_predict(neural_clf, X_train, y_train, cv=3, method=\"predict_proba\")\n",
    "naives_y_scores = cross_val_predict(nav_clf, X_train, y_train, cv=3, method=\"predict_proba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a6a8126ddba06457326cffc0da5947541f0c1055"
   },
   "outputs": [],
   "source": [
    "# hack to work around issue #9589 introduced in Scikit-Learn 0.19.0\n",
    "if y_scores.ndim == 2:\n",
    "    y_scores = y_scores[:, 1]\n",
    "\n",
    "if neural_y_scores.ndim == 2:\n",
    "    neural_y_scores = neural_y_scores[:, 1]\n",
    "    \n",
    "if naives_y_scores.ndim == 2:\n",
    "    naives_y_scores = naives_y_scores[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ca20fa57c7671c993bf3e7e6180f3b387feea9d6"
   },
   "outputs": [],
   "source": [
    "y_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8c13dce9fd373ad6716bc28928097ba71c6c52a5"
   },
   "outputs": [],
   "source": [
    "# How can we decide which threshold to use? We want to return the scores instead of predictions with this code.\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precisions, recalls, threshold = precision_recall_curve(y_train, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d18db09d3cae0cdf72ff7b8d1bd6c54631713c4d"
   },
   "outputs": [],
   "source": [
    "def precision_recall_curve(precisions, recalls, thresholds):\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    plt.plot(thresholds, precisions[:-1], \"r--\", label=\"Precisions\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"#424242\", label=\"Recalls\")\n",
    "    plt.title(\"Precision and Recall \\n Tradeoff\", fontsize=18)\n",
    "    plt.ylabel(\"Level of Precision and Recall\", fontsize=16)\n",
    "    plt.xlabel(\"Thresholds\", fontsize=16)\n",
    "    plt.legend(loc=\"best\", fontsize=14)\n",
    "    plt.xlim([-2, 4.7])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.axvline(x=0.13, linewidth=3, color=\"#0B3861\")\n",
    "    plt.annotate('Best Precision and \\n Recall Balance \\n is at 0.13 \\n threshold ', xy=(0.13, 0.83), xytext=(55, -40),\n",
    "             textcoords=\"offset points\",\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "                fontsize=12, \n",
    "                color='k')\n",
    "    \n",
    "precision_recall_curve(precisions, recalls, threshold)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7ecd4d6606c77ebc131379b0c3243c9ac3ecb84c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "# Gradient Boosting Classifier\n",
    "# Neural Classifier\n",
    "# Naives Bayes Classifier\n",
    "grd_fpr, grd_tpr, thresold = roc_curve(y_train, y_scores)\n",
    "neu_fpr, neu_tpr, neu_threshold = roc_curve(y_train, neural_y_scores)\n",
    "nav_fpr, nav_tpr, nav_threshold = roc_curve(y_train, naives_y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "990f2ac8ff9e21e3fcd6c105cd13bba89cda64db"
   },
   "outputs": [],
   "source": [
    "def graph_roc_curve(false_positive_rate, true_positive_rate, label=None):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.title('ROC Curve \\n Gradient Boosting Classifier', fontsize=18)\n",
    "    plt.plot(false_positive_rate, true_positive_rate, label=label)\n",
    "    plt.plot([0, 1], [0, 1], '#0C8EE0')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "    plt.annotate('ROC Score of 91.73% \\n (Not the best score)', xy=(0.25, 0.9), xytext=(0.4, 0.85),\n",
    "            arrowprops=dict(facecolor='#F75118', shrink=0.05),\n",
    "            )\n",
    "    plt.annotate('Minimum ROC Score of 50% \\n (This is the minimum score to get)', xy=(0.5, 0.5), xytext=(0.6, 0.3),\n",
    "                arrowprops=dict(facecolor='#F75118', shrink=0.05),\n",
    "                )\n",
    "    \n",
    "    \n",
    "graph_roc_curve(grd_fpr, grd_tpr, threshold)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cd3b8c8d192d32ae5afecf0b74ee1f0b39ff529b"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print('Gradient Boost Classifier Score: ', roc_auc_score(y_train, y_scores))\n",
    "print('Neural Classifier Score: ', roc_auc_score(y_train, neural_y_scores))\n",
    "print('Naives Bayes Classifier: ', roc_auc_score(y_train, naives_y_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ad2e0880fb975987a696a1d092b5eb67cea6f378"
   },
   "outputs": [],
   "source": [
    "def graph_roc_curve_multiple(grd_fpr, grd_tpr, neu_fpr, neu_tpr, nav_fpr, nav_tpr):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.title('ROC Curve \\n Top 3 Classifiers', fontsize=18)\n",
    "    plt.plot(grd_fpr, grd_tpr, label='Gradient Boosting Classifier (Score = 91.72%)')\n",
    "    plt.plot(neu_fpr, neu_tpr, label='Neural Classifier (Score = 91.54%)')\n",
    "    plt.plot(nav_fpr, nav_tpr, label='Naives Bayes Classifier (Score = 80.33%)')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)\n",
    "    plt.annotate('Minimum ROC Score of 50% \\n (This is the minimum score to get)', xy=(0.5, 0.5), xytext=(0.6, 0.3),\n",
    "                arrowprops=dict(facecolor='#6E726D', shrink=0.05),\n",
    "                )\n",
    "    plt.legend()\n",
    "    \n",
    "graph_roc_curve_multiple(grd_fpr, grd_tpr, neu_fpr, neu_tpr, nav_fpr, nav_tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bcc1233c7e65d9f707dd8016e07960ba538610b2"
   },
   "outputs": [],
   "source": [
    "grad_clf.predict_proba([some_instance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c7a26b34b6c2a135f7146161a662d1a11217b200"
   },
   "outputs": [],
   "source": [
    "# Let's see what does our classifier predict.\n",
    "grad_clf.predict([some_instance]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "faa5bcf945021f81cbe60cac4824008948d07c3c"
   },
   "outputs": [],
   "source": [
    "y_train[1250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b6c6ae762fbc230e70f6aa8edbb912915a86b6e7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "# Convert the columns into categorical variables\n",
    "term_deposits['job'] = term_deposits['job'].astype('category').cat.codes\n",
    "term_deposits['marital'] = term_deposits['marital'].astype('category').cat.codes\n",
    "term_deposits['education'] = term_deposits['education'].astype('category').cat.codes\n",
    "term_deposits['contact'] = term_deposits['contact'].astype('category').cat.codes\n",
    "term_deposits['poutcome'] = term_deposits['poutcome'].astype('category').cat.codes\n",
    "term_deposits['month'] = term_deposits['month'].astype('category').cat.codes\n",
    "term_deposits['default'] = term_deposits['default'].astype('category').cat.codes\n",
    "term_deposits['loan'] = term_deposits['loan'].astype('category').cat.codes\n",
    "term_deposits['housing'] = term_deposits['housing'].astype('category').cat.codes\n",
    "\n",
    "# Let's create new splittings like before but now we modified the data so we need to do it one more time.\n",
    "# Create train and test splits\n",
    "target_name = 'deposit'\n",
    "X = term_deposits.drop('deposit', axis=1)\n",
    "\n",
    "\n",
    "label=term_deposits[target_name]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,label,test_size=0.2, random_state=42, stratify=label)\n",
    "\n",
    "# Build a classification task using 3 informative features\n",
    "tree = tree.DecisionTreeClassifier(\n",
    "    class_weight='balanced',\n",
    "    min_weight_fraction_leaf = 0.01\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "tree = tree.fit(X_train, y_train)\n",
    "importances = tree.feature_importances_\n",
    "feature_names = term_deposits.drop('deposit', axis=1).columns\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "def feature_importance_graph(indices, importances, feature_names):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.title(\"Determining Feature importances \\n with DecisionTreeClassifier\", fontsize=18)\n",
    "    plt.barh(range(len(indices)), importances[indices], color='#31B173',  align=\"center\")\n",
    "    plt.yticks(range(len(indices)), feature_names[indices], rotation='horizontal',fontsize=14)\n",
    "    plt.ylim([-1, len(indices)])\n",
    "    plt.axhline(y=1.85, xmin=0.21, xmax=0.952, color='k', linewidth=3, linestyle='--')\n",
    "    plt.text(0.30, 2.8, '46% Difference between \\n duration and contacts', color='k', fontsize=15)\n",
    "    \n",
    "feature_importance_graph(indices, importances, feature_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "879e426aea63e85a90e130492b06ebb41784834f"
   },
   "outputs": [],
   "source": [
    "# Our three classifiers are grad_clf, nav_clf and neural_clf\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('gbc', grad_clf), ('nav', nav_clf), ('neural', neural_clf)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9dfa86f6976cce98556d1ccca366d8e562681f7c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (grad_clf, nav_clf, neural_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    predict = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
